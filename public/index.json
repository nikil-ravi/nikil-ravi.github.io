[{"content":"This post is mostly to jot down some thoughts on the evaluations space in AI right now. I\u0026rsquo;m going to write these points down as bullet points, so these are going to be more structured thoughts, than a cohesive article.\nMy mental model of evals: a conversation with model developers: I (currently) view evaluations as a conversation between model developers and the broader community. Roughly speaking, a benchmark is just a way to organize a complaint about the capabilities of current models. This benchmark then serves as an incentive for the model developer to improve their model (as measured by the benchmark), especially if the benchmark score is then going to be used by enterprises and consumers in deciding whether to use their model over someone else\u0026rsquo;s model. The cycle is then essentially of the form: model developer releases model x.v1 -\u0026gt; academia and evaluators release benchmarks showing areas to improve on -\u0026gt; model developer uses these benchmarks to release x.v2 that performs better on these benchmarks -\u0026gt; \u0026hellip;.. Of course, the other role these benchmarks play is to serve as a marker of the capabilities of the models, and can be used to make business decisions about their use, as well as larger societal decisions about how they integrate into the world around us.\nIt is actually quite cool and underappreciated that they correlate with anecdotal experience using the AI systems: I find it cool that benchmark scores roughly correlate with our impressions using these models. I find it a nice property of our current evaluations that one can infer from a 15-point gap in SWE-bench which model is likely better for coding, and that this is actually (mostly) a reasonable conclusion to make. There is a parallel universe where we did not have this property. Benchmarks that have this property (significantly higher score =\u0026gt; model is better to use for that task) are quite useful.\nRole of an evaluator: The role of a neutral third-party evaluator is:\nAs models get released, run evaluations on them and surface the results to the broader community in as neutral and useful a way as possible. create new evaluations that surface surprising aspects of the systems that are evaluated; this includes both deficiencies as well as things that the systems are surprisingly good at help the broader AI community and society interpret the results of the evaluations. Right now, we (the AI community) run a bunch of benchmarks, as a result of which we essentially get a table of numbers. This table of numbers is basically gibberish to the average person trying to get a sense of how good these systems are. Evaluators can help here by being the bridge between these numbers and the consumers of these numbers. analyze and surface insights about aspects of the AI systems other than the raw evaluation scores; this includes things like cost, latency, interesting failure modes, whether the model weights, training/inference code, and scaffolding code is available publicly, and other such information. make the traces corresponding to these evaluations public, and release tooling to be able to usefully engage with these traces. be transparent about the infrastructure used to evaluate models (endpoints, inference code, evaluation settings, scaffolding used, etc.). Some unanswered questions: What paradigms are currently missing from evaluation today? What is the longer term way to evaluate AI systems? When we run evaluations on AI models, what are we actually measuring? I do not know the answers here; I was recently reading a\n","permalink":"http://localhost:1313/thoughts/scattered-thoughts-evals/","summary":"\u003cp\u003eThis post is mostly to jot down some thoughts on the evaluations space in AI right now. I\u0026rsquo;m going to write these points down as bullet points, so these are going to be more structured thoughts, than a cohesive article.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eMy mental model of evals: a conversation with model developers\u003c/em\u003e: I (currently) view evaluations as a conversation between\nmodel developers and the broader community. Roughly speaking, a benchmark is just a way to organize a complaint about the capabilities of current models. This benchmark then serves as an incentive for the model developer to improve their model (as measured by the benchmark), especially if the benchmark score is then going to be used by enterprises and consumers in deciding whether to use their model over someone else\u0026rsquo;s model. The cycle is then essentially of the form: model developer releases model x.v1 -\u0026gt; academia and evaluators release benchmarks showing areas to improve on -\u0026gt; model developer uses these benchmarks to release x.v2 that performs better on these benchmarks -\u0026gt; \u0026hellip;..\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOf course, the other role these benchmarks play is to serve as a marker of the capabilities of the models, and can be used to make business decisions about their use, as well as larger societal decisions about how they integrate into the world around us.\u003c/p\u003e","title":"Scattered Thoughts on Evals"},{"content":"Introduction Autoformalization is the process of converting informal statements into formal programs automatically. While this in itself is not a very precise definition, in essence it refers to the process of removing ambiguity from a statement. There are multiple reasons why autoformalization is important: for instance, in order to accelerate mathematical advancement via artificial intelligence, one needs to be able to automatically (formally) state problems one is interested in. It is also likely that improved autoformalization capabilities will help us make progress with the issues surrounding AI safety- in order to see this, readers are urged to reframe the problem of autoformalization as the problem of trying address the following issue: \u0026ldquo;Can a sufficiently motivated adversary deliberately or accidentally misinterpret a natural language statement that is given to it?\u0026rdquo;. Formalization gives us a mechanism to guarantee only one possible interpretation of a statement, and therefore is likely to be a useful accelerant in finding good solutions to the problem of aligning AI systems.\nIn recent years, work in autoformalization has increasingly leveraged large language models (LLMs), and systems that scaffold LLMs, to achieve improvements in how well we can autoformalize statements.\nThese advances, while wonderful, still do not address one of the main bottlenecks of autoformalization\u0026ndash; how can we evaluate an autoformalized statement? Unlike automated theorem-proving, or even many coding tasks, where we can have a clear and unambiguous success signal, autoformalization does not come with any such simple metric of success. In other words, given a natural language statement $s$, and an autoformalization system $A(\\cdot)$, that produces a formalization $f$, it is not clear what it means to conclude that $f$ is correct or incorrect. Currently, humans simply manually verify the formalization.\nOne way to help diagnose issues is to observe that autoformalization is often done one not just a single statements but multiple related statements (eg. a chapter of a book, a mathematical research paper, etc.). When autoformalizing multiple statements at a time instead of just one, we can leverage dependencies between statements to identify potential mis-formalizations.\nConcretely, suppose we have two informal statements, say $s_1$ and $s_2$, with formalizations $f_1 = A(s_1)$ and $f_2 = A(s_2)$. Suppose also that we know (as an informal statement) that one implies the other (say $s_1 \\Rightarrow s_2$). Then, if we are able to find a proof that $f_1$ does not necessarily imply $f_2$, then we know that at least one of the formalizations must be incorrect. While this does not say which of them is incorrect, it can serve as a useful mechanism for users of an autoformalization system to (a) have increased confidence in the system, and (b) to identify incorrect formalizations of the form above.\nAn example of the intended approach:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import Mathlib.Data.Nat.Prime.Basic import Mathlib.Data.Nat.Basic import Mathlib.Tactic /-- Mis-formalized version of Euclid\u0026#39;s lemma dropping the `Prime p` assumption. -/ def A_bad (p a b : ℕ) : Prop := p ∣ a * b → (p ∣ a ∨ p ∣ b) /-- Derived statement B: if p divides a * b and p does not divide a, then p divides b. -/ def B_bad (p a b : ℕ) : Prop := p ∣ a * b → ¬ (p ∣ a) → (p ∣ b) /-- There exist p, a, b such that both A_bad and B_bad fail. This shows that there\u0026#39;s a misformalization in one of the statements above -/ theorem counterexample_A_bad_and_B_bad : ∃ (p a b : ℕ), ¬ A_bad p a b ∧ ¬ B_bad p a b := by -- choose p = 4, a = 2, b = 2 use 4, 2, 2 have hdiv : 4 ∣ (2 * 2) := by norm_num -- show ¬ A_bad 4 2 2 have hNotA : ¬ A_bad 4 2 2 := by rw [A_bad] intro h have : 4 ∣ 2 ∨ 4 ∣ 2 := h hdiv norm_num at this -- show ¬ B_bad 4 2 2 have hNotB : ¬ B_bad 4 2 2 := by intro hB -- hB : 4 ∣ (2 * 2) → ¬ (4 ∣ 2) → 4 ∣ 2 have h₂ := hB hdiv (by norm_num) -- h₂ : 4 ∣ 2, but 4 ∤ 2 norm_num at h₂ exact ⟨hNotA, hNotB⟩ ","permalink":"http://localhost:1313/thoughts/autodep/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eAutoformalization is the process of converting informal statements into formal programs automatically. While this in itself is not a very precise definition, in essence it refers to the process of removing ambiguity from a statement. There are multiple reasons why autoformalization is important: for instance, in order to accelerate mathematical advancement via artificial intelligence, one needs to be able to automatically (formally) state problems one is interested in. It is also likely that improved autoformalization capabilities will help us make progress with the issues surrounding AI safety- in order to see this, readers are urged to reframe the problem of autoformalization as the problem of trying address the following issue: \u003cem\u003e\u0026ldquo;Can a sufficiently motivated adversary deliberately or accidentally misinterpret a natural language statement that is given to it?\u0026rdquo;\u003c/em\u003e. Formalization gives us a mechanism to guarantee only one possible interpretation of a statement, and therefore is likely to be a useful accelerant in finding good solutions to the problem of aligning AI systems.\u003c/p\u003e","title":"Diagnosing autoformalizations via implication graph checks"},{"content":"Author: Erdal Arıkan\nPublication: IEEE Transactions on Information Theory, 2009\nLink: IEEE Xplore\nThis paper introduces polar codes, the first explicit and efficient code construction that achieves Shannon capacity for binary-input symmetric memoryless channels.\nThe main idea is channel polarization: by combining channels with a simple linear transform and applying the process recursively, one produces synthetic sub-channels that become either nearly perfect (capacity ≈ 1) or nearly useless (capacity ≈ 0)- hence the term polarization.\nEncoding is based on repeated Kronecker products of the matrix [ G_2 = \\begin{bmatrix} 1 \u0026amp; 1 \\ 0 \u0026amp; 1 \\end{bmatrix}, ] leading to a circuit with (O(N \\log N)) complexity. Decoding is carried out via successive cancellation, where each bit is decoded sequentially using previously decoded bits to improve reliability.\nThe intuition here is that the capacity is conserved, but we redistribute it using this construction such that the channels become polarized. This means that we eventually have sub-channels that have high capacity.\nIn particular, the result is that as (N) grows, the achievable rate approaches the channel capacity (C(W)) and the error probability vanishes. This provides a constructive and computationally efficient answer to Shannon’s existential theorem on reliable communication.\nPolar codes have also become practically important: they were adopted into the 5G wireless standard for control channels.\n","permalink":"http://localhost:1313/notes/polar-coding/","summary":"\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e Erdal Arıkan\u003cbr\u003e\n\u003cstrong\u003ePublication:\u003c/strong\u003e IEEE Transactions on Information Theory, 2009\u003cbr\u003e\n\u003cstrong\u003eLink:\u003c/strong\u003e \u003ca href=\"https://ieeexplore.ieee.org/document/4787611\"\u003eIEEE Xplore\u003c/a\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eThis paper introduces \u003cstrong\u003epolar codes\u003c/strong\u003e, the first explicit and efficient code construction that achieves Shannon capacity for binary-input symmetric memoryless channels.\u003c/p\u003e\n\u003cp\u003eThe main idea is \u003cstrong\u003echannel polarization\u003c/strong\u003e: by combining channels with a simple linear transform and applying the process recursively, one produces synthetic sub-channels that become either nearly perfect (capacity ≈ 1) or nearly useless (capacity ≈ 0)- hence the term polarization.\u003c/p\u003e","title":"Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels"},{"content":"Author: Paul Benacerraf\nPublication: The Philosophical Review, 1965\nLink: The Philosophical Review\nThis is a compelling article about the nature of mathematical objects (here focusing the exposition on the natural numbers). Essentially, the paper argues that numbers cannot be any of their possible particular definitions (e.g., as particular sets, Church numbers, etc). Instead, when we talk of numbers, we speak of the abstract structure that relates them.\nSo 2 is neither $(s (s 0))$ nor ${\\varnothing, {\\varnothing}, {\\varnothing, {\\varnothing}}}$ \u0026ndash; not these particular objects, but the relation that 2 has to 1 and 0 and 3 and so on, in whatever definition you want to give to the whole system.\nThough not explicitly mentioned, the paper argues for the categorical point of view of mathematics, where numbers would be defined by their universal property, which all of the particular definitions can be shown to satisfy.\n","permalink":"http://localhost:1313/notes/what-numbers-could-not-be/","summary":"\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e Paul Benacerraf\u003cbr\u003e\n\u003cstrong\u003ePublication:\u003c/strong\u003e The Philosophical Review, 1965\u003cbr\u003e\n\u003cstrong\u003eLink:\u003c/strong\u003e \u003ca href=\"https://www.jstor.org/stable/2183530\"\u003eThe Philosophical Review\u003c/a\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eThis is a compelling article about the nature of mathematical objects (here focusing the exposition on the natural numbers). Essentially, the paper argues that numbers cannot be any of their possible particular definitions (e.g., as particular sets, Church numbers, etc). Instead, when we talk of numbers, we speak of the abstract structure that relates them.\u003c/p\u003e\n\u003cp\u003eSo 2 is neither $(s (s 0))$ nor ${\\varnothing, {\\varnothing}, {\\varnothing, {\\varnothing}}}$ \u0026ndash; not these particular objects, but the relation that 2 has to 1 and 0 and 3 and so on, in whatever definition you want to give to the whole system.\u003c/p\u003e","title":"What Numbers Could not Be"},{"content":"Introduction Information theory assumes that all information can be represented using bits; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\nMeasures of Information Intuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- in other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\nSuppose that $$U$$ is a random variable that may take on values in $$\\mathbb{U} := {1, 2, \\cdots r}$$.\nSelf-information The smaller the probability of $$u \\in \\mathbb{U}$$, the more surprised we\u0026rsquo;d be if that value were actually realized by $$U$$.\nThis is formalized by the notion of self-information, also known as the \u0026ldquo;surprise function\u0026rdquo; or simply as the \u0026ldquo;log loss\u0026rdquo;.\n$$s(u) := \\log \\frac{1}{p(u)}$$\nEntropy The entropy of $$U$$ is defined as the expected surprise over all the possible realizations of $U$.\n$$H(U) := \\mathbb{E}_{U}[s(u)]$$\nThis can be expanded out to its most canonical form:\n$$H(U) := \\sum_{u = 1}^{r} p(u) \\cdot log \\frac{1}{p(u)}$$\nLike other measures of quantities, entropy also has units- we refer to the units as bits/symbol for b = 2, nats/symbol for b = e, and bans/symbol for b = 10.\n\\TODO{Shannons, Hartleys}\nWe will also generalize $$H(U)$$ by defining $$H_q(U)$$; for a PMF $$q$$, which is possibly equal to $$p$$, $$H_q(U)$ := $\\sum_{u = 1}^{r} p(u) \\cdot log \\frac{1}{q(u)}$$. Intuitively, $$H_q$$ measures how surprised you are if you thought that $$U$$ comes from distribution $$q$$, but it was actually from $p$.\nWhen $$q = p$$, we these quantities are equal ($$H_q = H$$); in fact, we can even go further and say that $$H(U) \\leq H_q(U)$$, with equality iff $$q = p$$ (the proof is tied to the notion of relative entropy, which immediately follows this section). All this is saying is that you\u0026rsquo;re probably going to be more surprised if you got the distribution wrong.\nRelative Entropy Now that we introduced a distribution $q$, it is useful to define a version of entropy that is relative, instead of absolute. This notion, relative entropy, can also be thought of as a measure of the divergence of the two distributions- in other words, how different is $$q$$ with respect to $$p$$?\n$$ \\begin{align} D(p||q) \u0026amp;= H_q(U) - H(U)\\ \u0026amp;= \\mathbb{E}[\\log \\frac{1}{p(u)} - \\log \\frac{1}{q(u)}]\\ \u0026amp;= \\sum_{u=1}^{r} p(u) \\cdot \\left[ \\log \\frac{1}{p(u)} - \\log \\frac{1}{q(u)} \\right]\\ \u0026amp;= \\sum_{u=1}^{r} p(u) \\cdot \\left( \\log \\frac{q(u)}{p(u)} \\right)\n\\end{align} $$\nThis quantity is also known as the Kullback-Leibler Divergence, or simply KL Divergence. Note that it is not symmetric; $$D(p ||q)$$ is not equal to $$D(q||p)$$ unless $$q = p$$. This is why we refer to it as a divergence, and not a distance in the sense of a metric.\nThe entropy of a random variable $$U$$ is upper-bounded by $$\\log r$$ (proof idea: apply Jensen\u0026rsquo;s inequality, since we have an expectation and a log).\nJoint Entropy Mutual Information lol\nTypicality and the Asymptotic Equipartition Property Now that we\u0026rsquo;ve defined some basic notions of information and its measurement, we can ask questions of the following kind: what are the characteristics of unsurprising information? What kinds of sequences occur typically?\nAn answer to this question emerges in the notion of $$\\epsilon$$-typical sequences.\nTo add a table of contents to a post as a sidebar, simply add\n1 2 toc: sidebar: left to the front matter of the post. The table of contents will be automatically generated from the headings in the post. If you wish to display the sidebar to the right, simply change left to right.\nExample of Sub-Heading 1 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\nExample of another Sub-Heading 1 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\nCustomizing Your Table of Contents {:data-toc-text=\u0026ldquo;Customizing\u0026rdquo;}\nIf you want to learn more about how to customize the table of contents of your sidebar, you can check the bootstrap-toc documentation. Notice that you can even customize the text of the heading that will be displayed on the sidebar.\nExample of Sub-Heading 2 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\nExample of another Sub-Heading 2 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\n","permalink":"http://localhost:1313/thoughts/2024-07-15-vlms/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eInformation theory assumes that all information can be represented using \u003cem\u003ebits\u003c/em\u003e; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\u003c/p\u003e\n\u003ch1 id=\"measures-of-information\"\u003eMeasures of Information\u003c/h1\u003e\n\u003cp\u003eIntuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- in other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\u003c/p\u003e","title":"Vision Language Models"},{"content":"Introduction Information theory assumes that all information can be represented using bits; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\nMeasures of Information Intuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- the idea is that if you only saw what you already knew, then the content wasn\u0026rsquo;t very informative. In other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\nIn order to formalize the surprising-ness of information, we will first need to define a prior distribution with respect to which we define this quantity.\nSuppose that $U$ is a random variable that may take on values in $\\mathbb{U} := {1, 2, \\cdots r}$. Note the subtle difference in notation between them- this is going to be used throughout.\nSelf-information The smaller the probability of $u \\in \\mathbb{U}$, the more surprised we\u0026rsquo;d be if that value were actually realized by $U$.\nThis is formalized by the notion of self-information, also known as the \u0026ldquo;surprise function\u0026rdquo; or simply as the \u0026ldquo;log loss\u0026rdquo;.\n$$s(u) := \\log \\frac{1}{p(u)}$$\nEntropy The entropy of $U$ is defined as the expected surprise over all the possible realizations of $U$.\n$$H(U) := \\mathbb{E}_{U}[s(u)]$$\nThis can be expanded out to its most canonical form:\n$$H(U) := \\sum_{u = 1}^{r} p(u) \\cdot log \\frac{1}{p(u)}$$\nLike other measures of quantities, entropy also has units- we refer to the units as bits/symbol for b = 2, nats/symbol for b = e, and bans/symbol for b = 10.\nJoint Entropy Conditional Entropy Mutual Information Consider the scenario in which there are two random variables $U$ and $V$. Suppose you have no prior knowledge about the values of these random variables. In this case the joint entropy $H(U, V)$ gives you the amount of information required to describe both of them.\nAlternatively, let\u0026rsquo;s say that you already know the value of $U$ but not that of $V$. In this case, the amount of additional information required to also describe $V$ is the conditional entropy $H(V | U)$.\nFrom the chain rule, we know that $H(U, V) = H(U) + H(V | U)$. Therefore, knowing $U$ reduces the amount of information required to describe $V$ by exactly $H(V) - H(V | U)$. This quantity is called the mutual information:\n$$I(U; V) := H(V) - H(V | U)$$\nMutual information is always non-negative; this aligns with our intuition that knowing one random variable should never increase the surprise (i.e., required information) of another.\n","permalink":"http://localhost:1313/thoughts/2024-01-14-information-theory/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eInformation theory assumes that all information can be represented using \u003cem\u003ebits\u003c/em\u003e; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\u003c/p\u003e\n\u003ch1 id=\"measures-of-information\"\u003eMeasures of Information\u003c/h1\u003e\n\u003cp\u003eIntuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- the idea is that if you only saw what you already knew, then the content wasn\u0026rsquo;t very informative. In other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\u003c/p\u003e","title":"Information Theory"},{"content":"Introduction to Lean Lean is a functional programming language that doubles as an interactive theorem prover. It combines the elegance of functional programming with powerful formal verification capabilities, making it ideal for both software development and mathematical proofs.\nWhat is Lean? Lean was created by Leonardo de Moura at Microsoft Research and is now developed as an open-source project. Unlike traditional proof assistants like Coq or Isabelle, Lean emphasizes:\nPerformance: Fast compilation and execution Usability: Clean, readable syntax Interactivity: Real-time feedback and proof development Extensibility: Metaprogramming capabilities Basic Mathematical Expressions Lean supports mathematical notation seamlessly. Here are some examples:\nInline math: $\\alpha + \\beta$\nDisplay math: $$\\alpha + \\beta$$\nDefining Types In Lean, we use the inductive keyword to define new types. Here\u0026rsquo;s how we define the natural numbers:\n1 2 3 inductive Nat : Type | zero : Nat | succ : Nat → Nat This creates a type Nat with two constructors: zero and succ (successor).\nFunctions and Recursion We can define functions using pattern matching and recursion:\n1 2 3 4 def add (n m : Nat) : Nat := match n with | zero =\u0026gt; m | succ n\u0026#39; =\u0026gt; succ (add n\u0026#39; m) This defines addition recursively: add n m adds n and m by repeatedly applying the successor function.\nTheorem Proving One of Lean\u0026rsquo;s most powerful features is its theorem proving capabilities. Here\u0026rsquo;s a simple proof by induction:\n1 2 3 4 5 6 theorem add_zero (n : Nat) : add n zero = n := by induction n case zero =\u0026gt; rfl -- reflexive equality, since add zero zero = zero case succ n\u0026#39; ih =\u0026gt; rw [add, ih] -- rewrite using the inductive hypothesis This theorem states that adding zero to any natural number n gives back n. The proof uses mathematical induction:\nBase case: When n = zero, we have add zero zero = zero by definition Inductive step: Assuming add n' zero = n' for some n', we show add (succ n') zero = succ n' Why Lean Matters Lean is particularly valuable because:\nFormal Verification: Prove code correctness mathematically Education: Learn programming and logic simultaneously Research: Build new mathematical theories and verify them Industry: Ensure critical software systems are bug-free Getting Started To install Lean, you can use the official installer or package managers:\n1 2 3 4 5 6 # Using curl curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh # Or using package managers # macOS with Homebrew: brew install lean # Ubuntu/Debian: sudo apt install lean Then create your first Lean file:\n1 2 3 def hello := \u0026#34;Hello, Lean!\u0026#34; #eval hello -- This will print \u0026#34;Hello, Lean!\u0026#34; Next Steps This post only scratches the surface of what Lean can do. In future posts, we\u0026rsquo;ll explore:\nDependent types and their applications Advanced theorem proving techniques Building verified data structures Integration with other programming languages Lean represents the future of software development where correctness is guaranteed through mathematical proof rather than just testing.\n","permalink":"http://localhost:1313/thoughts/intro-to-lean/","summary":"\u003ch1 id=\"introduction-to-lean\"\u003eIntroduction to Lean\u003c/h1\u003e\n\u003cp\u003eLean is a functional programming language that doubles as an interactive theorem prover. It combines the elegance of functional programming with powerful formal verification capabilities, making it ideal for both software development and mathematical proofs.\u003c/p\u003e\n\u003ch2 id=\"what-is-lean\"\u003eWhat is Lean?\u003c/h2\u003e\n\u003cp\u003eLean was created by Leonardo de Moura at Microsoft Research and is now developed as an open-source project. Unlike traditional proof assistants like Coq or Isabelle, Lean emphasizes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePerformance\u003c/strong\u003e: Fast compilation and execution\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUsability\u003c/strong\u003e: Clean, readable syntax\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInteractivity\u003c/strong\u003e: Real-time feedback and proof development\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExtensibility\u003c/strong\u003e: Metaprogramming capabilities\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"basic-mathematical-expressions\"\u003eBasic Mathematical Expressions\u003c/h2\u003e\n\u003cp\u003eLean supports mathematical notation seamlessly. Here are some examples:\u003c/p\u003e","title":"Introduction to Lean"},{"content":"This post is mostly to jot down some thoughts on the evaluations space in AI right now. I\u0026rsquo;m going to write these points down as bullet points, so these are going to be more structured thoughts, than a cohesive article.\nMy mental model of evals: a conversation with model developers: I (currently) view evaluations as a conversation between model developers and the broader community. Roughly speaking, a benchmark is just a way to organize a complaint about the capabilities of current models. This benchmark then serves as an incentive for the model developer to improve their model (as measured by the benchmark), especially if the benchmark score is then going to be used by enterprises and consumers in deciding whether to use their model over someone else\u0026rsquo;s model. The cycle is then essentially of the form: model developer releases model x.v1 -\u0026gt; academia and evaluators release benchmarks showing areas to improve on -\u0026gt; model developer uses these benchmarks to release x.v2 that performs better on these benchmarks -\u0026gt; \u0026hellip;.. Of course, the other role these benchmarks play is to serve as a marker of the capabilities of the models, and can be used to make business decisions about their use, as well as larger societal decisions about how they integrate into the world around us.\nIt is actually quite cool and underappreciated that they correlate with anecdotal experience using the AI systems: I find it cool that benchmark scores roughly correlate with our impressions using these models. I find it a nice property of our current evaluations that one can infer from a 15-point gap in SWE-bench which model is likely better for coding, and that this is actually (mostly) a reasonable conclusion to make. There is a parallel universe where we did not have this property. Benchmarks that have this property (significantly higher score =\u0026gt; model is better to use for that task) are quite useful.\nRole of an evaluator: The role of a neutral third-party evaluator is:\nAs models get released, run evaluations on them and surface the results to the broader community in as neutral and useful a way as possible. create new evaluations that surface surprising aspects of the systems that are evaluated; this includes both deficiencies as well as things that the systems are surprisingly good at help the broader AI community and society interpret the results of the evaluations. Right now, we (the AI community) run a bunch of benchmarks, as a result of which we essentially get a table of numbers. This table of numbers is basically gibberish to the average person trying to get a sense of how good these systems are. Evaluators can help here by being the bridge between these numbers and the consumers of these numbers. analyze and surface insights about aspects of the AI systems other than the raw evaluation scores; this includes things like cost, latency, interesting failure modes, whether the model weights, training/inference code, and scaffolding code is available publicly, and other such information. make the traces corresponding to these evaluations public, and release tooling to be able to usefully engage with these traces. be transparent about the infrastructure used to evaluate models (endpoints, inference code, evaluation settings, scaffolding used, etc.). Some unanswered questions: What paradigms are currently missing from evaluation today? What is the longer term way to evaluate AI systems? When we run evaluations on AI models, what are we actually measuring? I do not know the answers here; I was recently reading a\n","permalink":"http://localhost:1313/thoughts/scattered-thoughts-evals/","summary":"\u003cp\u003eThis post is mostly to jot down some thoughts on the evaluations space in AI right now. I\u0026rsquo;m going to write these points down as bullet points, so these are going to be more structured thoughts, than a cohesive article.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eMy mental model of evals: a conversation with model developers\u003c/em\u003e: I (currently) view evaluations as a conversation between\nmodel developers and the broader community. Roughly speaking, a benchmark is just a way to organize a complaint about the capabilities of current models. This benchmark then serves as an incentive for the model developer to improve their model (as measured by the benchmark), especially if the benchmark score is then going to be used by enterprises and consumers in deciding whether to use their model over someone else\u0026rsquo;s model. The cycle is then essentially of the form: model developer releases model x.v1 -\u0026gt; academia and evaluators release benchmarks showing areas to improve on -\u0026gt; model developer uses these benchmarks to release x.v2 that performs better on these benchmarks -\u0026gt; \u0026hellip;..\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOf course, the other role these benchmarks play is to serve as a marker of the capabilities of the models, and can be used to make business decisions about their use, as well as larger societal decisions about how they integrate into the world around us.\u003c/p\u003e","title":"Scattered Thoughts on Evals"},{"content":"Introduction Autoformalization is the process of converting informal statements into formal programs automatically. While this in itself is not a very precise definition, in essence it refers to the process of removing ambiguity from a statement. There are multiple reasons why autoformalization is important: for instance, in order to accelerate mathematical advancement via artificial intelligence, one needs to be able to automatically (formally) state problems one is interested in. It is also likely that improved autoformalization capabilities will help us make progress with the issues surrounding AI safety- in order to see this, readers are urged to reframe the problem of autoformalization as the problem of trying address the following issue: \u0026ldquo;Can a sufficiently motivated adversary deliberately or accidentally misinterpret a natural language statement that is given to it?\u0026rdquo;. Formalization gives us a mechanism to guarantee only one possible interpretation of a statement, and therefore is likely to be a useful accelerant in finding good solutions to the problem of aligning AI systems.\nIn recent years, work in autoformalization has increasingly leveraged large language models (LLMs), and systems that scaffold LLMs, to achieve improvements in how well we can autoformalize statements.\nThese advances, while wonderful, still do not address one of the main bottlenecks of autoformalization\u0026ndash; how can we evaluate an autoformalized statement? Unlike automated theorem-proving, or even many coding tasks, where we can have a clear and unambiguous success signal, autoformalization does not come with any such simple metric of success. In other words, given a natural language statement $s$, and an autoformalization system $A(\\cdot)$, that produces a formalization $f$, it is not clear what it means to conclude that $f$ is correct or incorrect. Currently, humans simply manually verify the formalization.\nOne way to help diagnose issues is to observe that autoformalization is often done one not just a single statements but multiple related statements (eg. a chapter of a book, a mathematical research paper, etc.). When autoformalizing multiple statements at a time instead of just one, we can leverage dependencies between statements to identify potential mis-formalizations.\nConcretely, suppose we have two informal statements, say $s_1$ and $s_2$, with formalizations $f_1 = A(s_1)$ and $f_2 = A(s_2)$. Suppose also that we know (as an informal statement) that one implies the other (say $s_1 \\Rightarrow s_2$). Then, if we are able to find a proof that $f_1$ does not necessarily imply $f_2$, then we know that at least one of the formalizations must be incorrect. While this does not say which of them is incorrect, it can serve as a useful mechanism for users of an autoformalization system to (a) have increased confidence in the system, and (b) to identify incorrect formalizations of the form above.\nAn example of the intended approach:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import Mathlib.Data.Nat.Prime.Basic import Mathlib.Data.Nat.Basic import Mathlib.Tactic /-- Mis-formalized version of Euclid\u0026#39;s lemma dropping the `Prime p` assumption. -/ def A_bad (p a b : ℕ) : Prop := p ∣ a * b → (p ∣ a ∨ p ∣ b) /-- Derived statement B: if p divides a * b and p does not divide a, then p divides b. -/ def B_bad (p a b : ℕ) : Prop := p ∣ a * b → ¬ (p ∣ a) → (p ∣ b) /-- There exist p, a, b such that both A_bad and B_bad fail. This shows that there\u0026#39;s a misformalization in one of the statements above -/ theorem counterexample_A_bad_and_B_bad : ∃ (p a b : ℕ), ¬ A_bad p a b ∧ ¬ B_bad p a b := by -- choose p = 4, a = 2, b = 2 use 4, 2, 2 have hdiv : 4 ∣ (2 * 2) := by norm_num -- show ¬ A_bad 4 2 2 have hNotA : ¬ A_bad 4 2 2 := by rw [A_bad] intro h have : 4 ∣ 2 ∨ 4 ∣ 2 := h hdiv norm_num at this -- show ¬ B_bad 4 2 2 have hNotB : ¬ B_bad 4 2 2 := by intro hB -- hB : 4 ∣ (2 * 2) → ¬ (4 ∣ 2) → 4 ∣ 2 have h₂ := hB hdiv (by norm_num) -- h₂ : 4 ∣ 2, but 4 ∤ 2 norm_num at h₂ exact ⟨hNotA, hNotB⟩ ","permalink":"http://localhost:1313/thoughts/autodep/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eAutoformalization is the process of converting informal statements into formal programs automatically. While this in itself is not a very precise definition, in essence it refers to the process of removing ambiguity from a statement. There are multiple reasons why autoformalization is important: for instance, in order to accelerate mathematical advancement via artificial intelligence, one needs to be able to automatically (formally) state problems one is interested in. It is also likely that improved autoformalization capabilities will help us make progress with the issues surrounding AI safety- in order to see this, readers are urged to reframe the problem of autoformalization as the problem of trying address the following issue: \u003cem\u003e\u0026ldquo;Can a sufficiently motivated adversary deliberately or accidentally misinterpret a natural language statement that is given to it?\u0026rdquo;\u003c/em\u003e. Formalization gives us a mechanism to guarantee only one possible interpretation of a statement, and therefore is likely to be a useful accelerant in finding good solutions to the problem of aligning AI systems.\u003c/p\u003e","title":"Diagnosing autoformalizations via implication graph checks"},{"content":"Introduction Information theory assumes that all information can be represented using bits; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\nMeasures of Information Intuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- in other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\nSuppose that $$U$$ is a random variable that may take on values in $$\\mathbb{U} := {1, 2, \\cdots r}$$.\nSelf-information The smaller the probability of $$u \\in \\mathbb{U}$$, the more surprised we\u0026rsquo;d be if that value were actually realized by $$U$$.\nThis is formalized by the notion of self-information, also known as the \u0026ldquo;surprise function\u0026rdquo; or simply as the \u0026ldquo;log loss\u0026rdquo;.\n$$s(u) := \\log \\frac{1}{p(u)}$$\nEntropy The entropy of $$U$$ is defined as the expected surprise over all the possible realizations of $U$.\n$$H(U) := \\mathbb{E}_{U}[s(u)]$$\nThis can be expanded out to its most canonical form:\n$$H(U) := \\sum_{u = 1}^{r} p(u) \\cdot log \\frac{1}{p(u)}$$\nLike other measures of quantities, entropy also has units- we refer to the units as bits/symbol for b = 2, nats/symbol for b = e, and bans/symbol for b = 10.\n\\TODO{Shannons, Hartleys}\nWe will also generalize $$H(U)$$ by defining $$H_q(U)$$; for a PMF $$q$$, which is possibly equal to $$p$$, $$H_q(U)$ := $\\sum_{u = 1}^{r} p(u) \\cdot log \\frac{1}{q(u)}$$. Intuitively, $$H_q$$ measures how surprised you are if you thought that $$U$$ comes from distribution $$q$$, but it was actually from $p$.\nWhen $$q = p$$, we these quantities are equal ($$H_q = H$$); in fact, we can even go further and say that $$H(U) \\leq H_q(U)$$, with equality iff $$q = p$$ (the proof is tied to the notion of relative entropy, which immediately follows this section). All this is saying is that you\u0026rsquo;re probably going to be more surprised if you got the distribution wrong.\nRelative Entropy Now that we introduced a distribution $q$, it is useful to define a version of entropy that is relative, instead of absolute. This notion, relative entropy, can also be thought of as a measure of the divergence of the two distributions- in other words, how different is $$q$$ with respect to $$p$$?\n$$ \\begin{align} D(p||q) \u0026amp;= H_q(U) - H(U)\\ \u0026amp;= \\mathbb{E}[\\log \\frac{1}{p(u)} - \\log \\frac{1}{q(u)}]\\ \u0026amp;= \\sum_{u=1}^{r} p(u) \\cdot \\left[ \\log \\frac{1}{p(u)} - \\log \\frac{1}{q(u)} \\right]\\ \u0026amp;= \\sum_{u=1}^{r} p(u) \\cdot \\left( \\log \\frac{q(u)}{p(u)} \\right)\n\\end{align} $$\nThis quantity is also known as the Kullback-Leibler Divergence, or simply KL Divergence. Note that it is not symmetric; $$D(p ||q)$$ is not equal to $$D(q||p)$$ unless $$q = p$$. This is why we refer to it as a divergence, and not a distance in the sense of a metric.\nThe entropy of a random variable $$U$$ is upper-bounded by $$\\log r$$ (proof idea: apply Jensen\u0026rsquo;s inequality, since we have an expectation and a log).\nJoint Entropy Mutual Information lol\nTypicality and the Asymptotic Equipartition Property Now that we\u0026rsquo;ve defined some basic notions of information and its measurement, we can ask questions of the following kind: what are the characteristics of unsurprising information? What kinds of sequences occur typically?\nAn answer to this question emerges in the notion of $$\\epsilon$$-typical sequences.\nTo add a table of contents to a post as a sidebar, simply add\n1 2 toc: sidebar: left to the front matter of the post. The table of contents will be automatically generated from the headings in the post. If you wish to display the sidebar to the right, simply change left to right.\nExample of Sub-Heading 1 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\nExample of another Sub-Heading 1 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\nCustomizing Your Table of Contents {:data-toc-text=\u0026ldquo;Customizing\u0026rdquo;}\nIf you want to learn more about how to customize the table of contents of your sidebar, you can check the bootstrap-toc documentation. Notice that you can even customize the text of the heading that will be displayed on the sidebar.\nExample of Sub-Heading 2 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\nExample of another Sub-Heading 2 Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.\n","permalink":"http://localhost:1313/thoughts/2024-07-15-vlms/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eInformation theory assumes that all information can be represented using \u003cem\u003ebits\u003c/em\u003e; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\u003c/p\u003e\n\u003ch1 id=\"measures-of-information\"\u003eMeasures of Information\u003c/h1\u003e\n\u003cp\u003eIntuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- in other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\u003c/p\u003e","title":"Vision Language Models"},{"content":"Introduction Information theory assumes that all information can be represented using bits; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\nMeasures of Information Intuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- the idea is that if you only saw what you already knew, then the content wasn\u0026rsquo;t very informative. In other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\nIn order to formalize the surprising-ness of information, we will first need to define a prior distribution with respect to which we define this quantity.\nSuppose that $U$ is a random variable that may take on values in $\\mathbb{U} := {1, 2, \\cdots r}$. Note the subtle difference in notation between them- this is going to be used throughout.\nSelf-information The smaller the probability of $u \\in \\mathbb{U}$, the more surprised we\u0026rsquo;d be if that value were actually realized by $U$.\nThis is formalized by the notion of self-information, also known as the \u0026ldquo;surprise function\u0026rdquo; or simply as the \u0026ldquo;log loss\u0026rdquo;.\n$$s(u) := \\log \\frac{1}{p(u)}$$\nEntropy The entropy of $U$ is defined as the expected surprise over all the possible realizations of $U$.\n$$H(U) := \\mathbb{E}_{U}[s(u)]$$\nThis can be expanded out to its most canonical form:\n$$H(U) := \\sum_{u = 1}^{r} p(u) \\cdot log \\frac{1}{p(u)}$$\nLike other measures of quantities, entropy also has units- we refer to the units as bits/symbol for b = 2, nats/symbol for b = e, and bans/symbol for b = 10.\nJoint Entropy Conditional Entropy Mutual Information Consider the scenario in which there are two random variables $U$ and $V$. Suppose you have no prior knowledge about the values of these random variables. In this case the joint entropy $H(U, V)$ gives you the amount of information required to describe both of them.\nAlternatively, let\u0026rsquo;s say that you already know the value of $U$ but not that of $V$. In this case, the amount of additional information required to also describe $V$ is the conditional entropy $H(V | U)$.\nFrom the chain rule, we know that $H(U, V) = H(U) + H(V | U)$. Therefore, knowing $U$ reduces the amount of information required to describe $V$ by exactly $H(V) - H(V | U)$. This quantity is called the mutual information:\n$$I(U; V) := H(V) - H(V | U)$$\nMutual information is always non-negative; this aligns with our intuition that knowing one random variable should never increase the surprise (i.e., required information) of another.\n","permalink":"http://localhost:1313/thoughts/2024-01-14-information-theory/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eInformation theory assumes that all information can be represented using \u003cem\u003ebits\u003c/em\u003e; a bit consists of either a 0 or a 1. We\u0026rsquo;d like ways to measure information, and also want techniques to represent and communicate it efficiently. In this post, we\u0026rsquo;ll be going over fundamental, well-established notions in information theory.\u003c/p\u003e\n\u003ch1 id=\"measures-of-information\"\u003eMeasures of Information\u003c/h1\u003e\n\u003cp\u003eIntuitively, a good measure of information would tell us only what we don\u0026rsquo;t know- the idea is that if you only saw what you already knew, then the content wasn\u0026rsquo;t very informative. In other words, a measure of information should take into account how \u0026ldquo;surprising\u0026rdquo; the information is.\u003c/p\u003e","title":"Information Theory"},{"content":"Introduction to Lean Lean is a functional programming language that doubles as an interactive theorem prover. It combines the elegance of functional programming with powerful formal verification capabilities, making it ideal for both software development and mathematical proofs.\nWhat is Lean? Lean was created by Leonardo de Moura at Microsoft Research and is now developed as an open-source project. Unlike traditional proof assistants like Coq or Isabelle, Lean emphasizes:\nPerformance: Fast compilation and execution Usability: Clean, readable syntax Interactivity: Real-time feedback and proof development Extensibility: Metaprogramming capabilities Basic Mathematical Expressions Lean supports mathematical notation seamlessly. Here are some examples:\nInline math: $\\alpha + \\beta$\nDisplay math: $$\\alpha + \\beta$$\nDefining Types In Lean, we use the inductive keyword to define new types. Here\u0026rsquo;s how we define the natural numbers:\n1 2 3 inductive Nat : Type | zero : Nat | succ : Nat → Nat This creates a type Nat with two constructors: zero and succ (successor).\nFunctions and Recursion We can define functions using pattern matching and recursion:\n1 2 3 4 def add (n m : Nat) : Nat := match n with | zero =\u0026gt; m | succ n\u0026#39; =\u0026gt; succ (add n\u0026#39; m) This defines addition recursively: add n m adds n and m by repeatedly applying the successor function.\nTheorem Proving One of Lean\u0026rsquo;s most powerful features is its theorem proving capabilities. Here\u0026rsquo;s a simple proof by induction:\n1 2 3 4 5 6 theorem add_zero (n : Nat) : add n zero = n := by induction n case zero =\u0026gt; rfl -- reflexive equality, since add zero zero = zero case succ n\u0026#39; ih =\u0026gt; rw [add, ih] -- rewrite using the inductive hypothesis This theorem states that adding zero to any natural number n gives back n. The proof uses mathematical induction:\nBase case: When n = zero, we have add zero zero = zero by definition Inductive step: Assuming add n' zero = n' for some n', we show add (succ n') zero = succ n' Why Lean Matters Lean is particularly valuable because:\nFormal Verification: Prove code correctness mathematically Education: Learn programming and logic simultaneously Research: Build new mathematical theories and verify them Industry: Ensure critical software systems are bug-free Getting Started To install Lean, you can use the official installer or package managers:\n1 2 3 4 5 6 # Using curl curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh # Or using package managers # macOS with Homebrew: brew install lean # Ubuntu/Debian: sudo apt install lean Then create your first Lean file:\n1 2 3 def hello := \u0026#34;Hello, Lean!\u0026#34; #eval hello -- This will print \u0026#34;Hello, Lean!\u0026#34; Next Steps This post only scratches the surface of what Lean can do. In future posts, we\u0026rsquo;ll explore:\nDependent types and their applications Advanced theorem proving techniques Building verified data structures Integration with other programming languages Lean represents the future of software development where correctness is guaranteed through mathematical proof rather than just testing.\n","permalink":"http://localhost:1313/thoughts/intro-to-lean/","summary":"\u003ch1 id=\"introduction-to-lean\"\u003eIntroduction to Lean\u003c/h1\u003e\n\u003cp\u003eLean is a functional programming language that doubles as an interactive theorem prover. It combines the elegance of functional programming with powerful formal verification capabilities, making it ideal for both software development and mathematical proofs.\u003c/p\u003e\n\u003ch2 id=\"what-is-lean\"\u003eWhat is Lean?\u003c/h2\u003e\n\u003cp\u003eLean was created by Leonardo de Moura at Microsoft Research and is now developed as an open-source project. Unlike traditional proof assistants like Coq or Isabelle, Lean emphasizes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePerformance\u003c/strong\u003e: Fast compilation and execution\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUsability\u003c/strong\u003e: Clean, readable syntax\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInteractivity\u003c/strong\u003e: Real-time feedback and proof development\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExtensibility\u003c/strong\u003e: Metaprogramming capabilities\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"basic-mathematical-expressions\"\u003eBasic Mathematical Expressions\u003c/h2\u003e\n\u003cp\u003eLean supports mathematical notation seamlessly. Here are some examples:\u003c/p\u003e","title":"Introduction to Lean"}]